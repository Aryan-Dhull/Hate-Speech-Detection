{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport re\nimport string\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.metrics import classification_report, accuracy_score,f1_score\nfrom transformers import AutoModel\nfrom transformers import BertModel, BertTokenizer\nfrom torch.utils.data import Dataset , DataLoader\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nclass BERT_Arch_CNN(nn.Module):\n\n    def __init__(self):\n        super(BERT_Arch_CNN, self).__init__()\n#         self.bert = BertModel.from_pretrained('bert-base-uncased')\n        self.conv = nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(3, 768), padding=1)\n        self.relu = nn.ReLU()\n        self.pool = nn.MaxPool2d(kernel_size=3, stride=1)\n        self.dropout = nn.Dropout(0.1)\n        self.fc = nn.Linear(624, 2) # before : 442 with max_length 36 # 806 with max_length 64\n        self.flat = nn.Flatten()\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, all_layers):\n        x = torch.transpose(torch.cat(tuple([t.unsqueeze(0) for t in all_layers]), 0), 0, 1)\n        torch.cuda.empty_cache()\n        x = self.pool(self.dropout(self.relu(self.conv(self.dropout(x)))))\n        x = self.fc(self.dropout(self.flat(self.dropout(x))))\n        return x","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-25T09:06:44.748487Z","iopub.execute_input":"2024-04-25T09:06:44.749449Z","iopub.status.idle":"2024-04-25T09:06:44.760174Z","shell.execute_reply.started":"2024-04-25T09:06:44.749417Z","shell.execute_reply":"2024-04-25T09:06:44.759170Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import datasets\n\ntrain_dataset = datasets.load_dataset('social_bias_frames',split=\"train[:12000]\")\nvalid_dataset = datasets.load_dataset('social_bias_frames',split=\"validation[:7000]\")\ntest_dataset = datasets.load_dataset('social_bias_frames',split=\"test[:7000]\")\n\n\n# train_df = train_dataset.to_pandas()\n# train_df = train_df[train_df['offensiveYN'] != '']\n# train_df.loc[train_df['offensiveYN'] == '0.5', 'offensiveYN'] = '1.0'\n\n# train_dataset = datasets.Dataset.from_pandas(train_df)\n\n# val_df = valid_dataset.to_pandas()\n# val_df = val_df[val_df['offensiveYN'] != '']\n# val_df.loc[val_df['offensiveYN'] == '0.5', 'offensiveYN'] = '1.0'\n\n# val_dataset = datasets.Dataset.from_pandas(val_df)\n\n# test_df = test_dataset.to_pandas()\n# test_df = test_df[test_df['offensiveYN'] != '']\n# test_df['offensiveYN'] = test_df['offensiveYN'].round(0)\n# test_df.loc[test_df['offensiveYN'] == '0.5', 'offensiveYN'] = '1.0'\n\n# test_dataset = datasets.Dataset.from_pandas(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T09:06:44.762386Z","iopub.execute_input":"2024-04-25T09:06:44.762673Z","iopub.status.idle":"2024-04-25T09:06:47.526942Z","shell.execute_reply.started":"2024-04-25T09:06:44.762651Z","shell.execute_reply":"2024-04-25T09:06:47.526012Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# label_encoder = LabelEncoder()\n# y_train=label_encoder.fit_transform(train_dataset['offensiveYN'])\n\n# label_encoder = LabelEncoder()\n# y_val=label_encoder.fit_transform(val_dataset['offensiveYN'])\n\n# label_encoder = LabelEncoder()\n# y_test=label_encoder.fit_transform(test_dataset['offensiveYN'])","metadata":{"execution":{"iopub.status.busy":"2024-04-25T09:06:47.528169Z","iopub.execute_input":"2024-04-25T09:06:47.528511Z","iopub.status.idle":"2024-04-25T09:06:47.533369Z","shell.execute_reply.started":"2024-04-25T09:06:47.528479Z","shell.execute_reply":"2024-04-25T09:06:47.532526Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class HateDataset(Dataset):\n    def __init__(self, dataset, tokenizer, model):\n        dataset = dataset.to_pandas()\n        dataset = dataset[dataset['offensiveYN'] != '']\n        dataset.loc[dataset['offensiveYN'] == '0.5', 'offensiveYN'] = '1.0'\n        dataset = dataset.groupby(['post','offensiveYN']).size().reset_index(name='counts')\n        dataset = dataset.sort_values('counts', ascending=False).drop_duplicates('post')\n\n        dataset = datasets.Dataset.from_pandas(dataset)\n        \n        label_encoder = LabelEncoder()\n        \n        self.label = label_encoder.fit_transform(dataset['offensiveYN'])\n        \n        self.post = dataset['post']\n        \n        self.tokenizer = tokenizer\n        self.model = model\n\n    def __len__(self):\n        return len(self.label)\n        \n    def __getitem__(self, idx):\n        # Tokenize the text\n        tokenized_post = self.tokenizer(self.post[idx], return_tensors='pt',max_length=50, padding='max_length', truncation=True)\n        \n#         # Forward pass through the model\n#         with torch.no_grad():\n#             model_output = self.model(**tokenized_post)\n        with torch.no_grad():\n            all_layers = self.model(input_ids=tokenized_post['input_ids'], attention_mask=tokenized_post['attention_mask'], output_hidden_states=True)\n        # Return label and last hidden state\n        return self.label[idx], all_layers.hidden_states","metadata":{"execution":{"iopub.status.busy":"2024-04-25T09:06:47.534645Z","iopub.execute_input":"2024-04-25T09:06:47.535222Z","iopub.status.idle":"2024-04-25T09:06:47.545079Z","shell.execute_reply.started":"2024-04-25T09:06:47.535192Z","shell.execute_reply":"2024-04-25T09:06:47.544259Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = BertModel.from_pretrained('bert-base-uncased')\n\ntraining_data = HateDataset(train_dataset,tokenizer,bert_model)\ntrain_dataloader = DataLoader(training_data , batch_size=1 , shuffle=True)\n\nvalidation_data = HateDataset(valid_dataset,tokenizer,bert_model)\nval_dataloader = DataLoader(validation_data , batch_size=1 , shuffle=False)\n\ntesting_data = HateDataset(test_dataset,tokenizer,bert_model)\ntest_dataloader = DataLoader(testing_data , batch_size=1 , shuffle=False)\n\nmodel = BERT_Arch()\nmodel = model.to(device)\n\n# optimizer from hugging face transformers\nfrom transformers import AdamW\n\n# define the optimizer\noptimizer = AdamW(model.parameters(), lr=2e-5)\ncriterion=nn.CrossEntropyLoss()\n\nfor epoch in range(10):\n    # Training phase\n    model.train()\n    train_running_loss = 0.0\n    train_all_predictions = []\n    train_all_labels = []\n\n    for labels, all_layers in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{10} - Training\"):\n        labels = torch.tensor(labels)\n        for i in range(len(all_layers)):\n            all_layers[i] = all_layers[i].squeeze().unsqueeze(0)\n        all_layers = torch.stack(all_layers)\n        all_layers = all_layers.to(device)\n        labels = labels.to(device)\n        model.zero_grad()\n        optimizer.zero_grad()\n\n        outputs = model(all_layers)\n#         print(outputs)\n        one_hot_targets = torch.zeros(1, 2).to(device)\n        one_hot_targets.scatter_(1, labels.unsqueeze(1), 1)\n        \n#         print(outputs)\n#         print(one_hot_targets)\n        \n        loss = criterion(outputs.squeeze(), one_hot_targets.squeeze())\n        loss.backward()\n        optimizer.step()\n\n        train_running_loss += loss.item()\n\n        predicted = torch.argmax(outputs, dim=1)\n        train_all_predictions.extend(predicted.cpu().tolist())\n        train_all_labels.extend(labels.cpu().tolist())\n\n    train_epoch_loss = train_running_loss / len(train_dataloader)\n#     print(train_all_labels)\n#     print(train_all_predictions)\n    train_epoch_accuracy = accuracy_score(train_all_labels, train_all_predictions)\n    train_epoch_f1 = f1_score(train_all_labels, train_all_predictions, average='macro')\n\n    print(f\"Epoch {epoch+1}/{10} - Training, Loss: {train_epoch_loss:.4f}, Accuracy: {train_epoch_accuracy:.4f}, F1: {train_epoch_f1:.4f}\")\n\n    # Validation phase\n    model.eval()\n    val_running_loss = 0.0\n    val_all_predictions = []\n    val_all_labels = []\n\n    with torch.no_grad():\n        for labels, all_layers in tqdm(val_dataloader, desc=f\"Epoch {epoch+1}/{10} - Validation\"):\n            labels = torch.tensor(labels)\n            for i in range(len(all_layers)):\n                all_layers[i] = all_layers[i].squeeze().unsqueeze(0)\n            all_layers = torch.stack(all_layers)\n            all_layers = all_layers.to(device)\n            labels=labels.to(device)\n#             inputs = torch.tensor(inputs[0])\n#             labels = torch.tensor([labels[0]])\n#             inputs = inputs.to(device)\n#             labels = labels.to(device)\n            outputs = model(all_layers)\n            one_hot_targets = torch.zeros(1, 2).to(device)\n            one_hot_targets.scatter_(1, labels.unsqueeze(1), 1)\n            loss = criterion(outputs.squeeze(), one_hot_targets.squeeze())\n\n            val_running_loss += loss.item()\n\n            predicted = torch.argmax(outputs, dim=1)\n            val_all_predictions.extend(predicted.cpu().tolist())\n            val_all_labels.extend(labels.cpu().tolist())\n\n        val_epoch_loss = val_running_loss / len(val_dataloader)\n        val_epoch_accuracy = accuracy_score(val_all_labels, val_all_predictions)\n        val_epoch_f1 = f1_score(val_all_labels, val_all_predictions, average='macro')\n\n        print(f\"Epoch {epoch+1}/{10} - Validation, Loss: {val_epoch_loss:.4f}, Accuracy: {val_epoch_accuracy:.4f}, F1: {val_epoch_f1:.4f}\")\n\n\n    torch.save(model.state_dict(), f'Model_BERT_CNN_{epoch+1}.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-25T09:06:47.546751Z","iopub.execute_input":"2024-04-25T09:06:47.547028Z","iopub.status.idle":"2024-04-25T10:44:45.162900Z","shell.execute_reply.started":"2024-04-25T09:06:47.547007Z","shell.execute_reply":"2024-04-25T10:44:45.161847Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nEpoch 1/10 - Training:   0%|          | 0/4083 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 1/10 - Training: 100%|██████████| 4083/4083 [06:36<00:00, 10.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 - Training, Loss: 0.5729, Accuracy: 0.7120, F1: 0.6385\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10 - Validation:   0%|          | 0/2037 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 1/10 - Validation: 100%|██████████| 2037/2037 [03:13<00:00, 10.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 - Validation, Loss: 0.6000, Accuracy: 0.6672, F1: 0.6666\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10 - Training:   0%|          | 0/4083 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 2/10 - Training: 100%|██████████| 4083/4083 [06:32<00:00, 10.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10 - Training, Loss: 0.4722, Accuracy: 0.7891, F1: 0.7458\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10 - Validation:   0%|          | 0/2037 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 2/10 - Validation: 100%|██████████| 2037/2037 [03:13<00:00, 10.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10 - Validation, Loss: 0.5946, Accuracy: 0.6706, F1: 0.6706\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10 - Training:   0%|          | 0/4083 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 3/10 - Training: 100%|██████████| 4083/4083 [06:35<00:00, 10.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10 - Training, Loss: 0.3950, Accuracy: 0.8246, F1: 0.7910\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10 - Validation:   0%|          | 0/2037 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 3/10 - Validation: 100%|██████████| 2037/2037 [03:14<00:00, 10.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10 - Validation, Loss: 0.6241, Accuracy: 0.6519, F1: 0.6515\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10 - Training:   0%|          | 0/4083 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 4/10 - Training: 100%|██████████| 4083/4083 [06:32<00:00, 10.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10 - Training, Loss: 0.3243, Accuracy: 0.8651, F1: 0.8416\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10 - Validation:   0%|          | 0/2037 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 4/10 - Validation: 100%|██████████| 2037/2037 [03:13<00:00, 10.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10 - Validation, Loss: 0.6636, Accuracy: 0.6539, F1: 0.6504\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10 - Training:   0%|          | 0/4083 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 5/10 - Training: 100%|██████████| 4083/4083 [06:34<00:00, 10.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10 - Training, Loss: 0.2520, Accuracy: 0.9033, F1: 0.8876\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10 - Validation:   0%|          | 0/2037 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 5/10 - Validation: 100%|██████████| 2037/2037 [03:13<00:00, 10.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10 - Validation, Loss: 0.6327, Accuracy: 0.6848, F1: 0.6848\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10 - Training:   0%|          | 0/4083 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 6/10 - Training: 100%|██████████| 4083/4083 [06:32<00:00, 10.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10 - Training, Loss: 0.1953, Accuracy: 0.9329, F1: 0.9230\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10 - Validation:   0%|          | 0/2037 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 6/10 - Validation: 100%|██████████| 2037/2037 [03:12<00:00, 10.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10 - Validation, Loss: 0.7355, Accuracy: 0.6573, F1: 0.6538\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10 - Training:   0%|          | 0/4083 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 7/10 - Training: 100%|██████████| 4083/4083 [06:32<00:00, 10.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10 - Training, Loss: 0.1503, Accuracy: 0.9513, F1: 0.9446\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10 - Validation:   0%|          | 0/2037 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 7/10 - Validation: 100%|██████████| 2037/2037 [03:12<00:00, 10.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10 - Validation, Loss: 0.8478, Accuracy: 0.6451, F1: 0.6367\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10 - Training:   0%|          | 0/4083 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 8/10 - Training: 100%|██████████| 4083/4083 [06:35<00:00, 10.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10 - Training, Loss: 0.1134, Accuracy: 0.9709, F1: 0.9670\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10 - Validation:   0%|          | 0/2037 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 8/10 - Validation: 100%|██████████| 2037/2037 [03:12<00:00, 10.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10 - Validation, Loss: 0.8069, Accuracy: 0.6642, F1: 0.6641\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10 - Training:   0%|          | 0/4083 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 9/10 - Training: 100%|██████████| 4083/4083 [06:35<00:00, 10.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10 - Training, Loss: 0.0906, Accuracy: 0.9758, F1: 0.9727\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10 - Validation:   0%|          | 0/2037 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 9/10 - Validation: 100%|██████████| 2037/2037 [03:16<00:00, 10.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10 - Validation, Loss: 0.7736, Accuracy: 0.6878, F1: 0.6876\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10 - Training:   0%|          | 0/4083 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 10/10 - Training: 100%|██████████| 4083/4083 [06:36<00:00, 10.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10 - Training, Loss: 0.0746, Accuracy: 0.9799, F1: 0.9774\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10 - Validation:   0%|          | 0/2037 [00:00<?, ?it/s]/tmp/ipykernel_34/1867055418.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  labels = torch.tensor(labels)\nEpoch 10/10 - Validation: 100%|██████████| 2037/2037 [03:12<00:00, 10.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10 - Validation, Loss: 0.8811, Accuracy: 0.6637, F1: 0.6636\n","output_type":"stream"}]}]}
