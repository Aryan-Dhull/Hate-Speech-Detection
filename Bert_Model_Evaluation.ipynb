{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "bBrckZLLteNP"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import classification_report, accuracy_score,f1_score\n",
        "from transformers import AutoModel\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from torch.utils.data import Dataset , DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import datasets\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = datasets.load_dataset('social_bias_frames',split=\"validation[:7000]\")\n",
        "test_dataset = datasets.load_dataset('social_bias_frames',split=\"test[:9000]\")"
      ],
      "metadata": {
        "id": "u-0cv7s7tv2s"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HateDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, model, max_length):\n",
        "        dataset = dataset.to_pandas()\n",
        "        dataset = dataset[dataset['offensiveYN'] != '']\n",
        "        dataset.loc[dataset['offensiveYN'] == '0.5', 'offensiveYN'] = '1.0'\n",
        "        dataset = dataset.groupby(['post','offensiveYN']).size().reset_index(name='counts')\n",
        "        dataset = dataset.sort_values('counts', ascending=False).drop_duplicates('post')\n",
        "        dataset = datasets.Dataset.from_pandas(dataset)\n",
        "        label_encoder = LabelEncoder()\n",
        "        self.label = label_encoder.fit_transform(dataset['offensiveYN'])\n",
        "        self.post = dataset['post']\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model = model\n",
        "        self.max_length=max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokenized_post = self.tokenizer(self.post[idx], return_tensors='pt',max_length=self.max_length, padding='max_length', truncation=True)\n",
        "        with torch.no_grad():\n",
        "            all_layers = self.model(input_ids=tokenized_post['input_ids'], attention_mask=tokenized_post['attention_mask'], output_hidden_states=True)\n",
        "        return self.label[idx], all_layers.hidden_states"
      ],
      "metadata": {
        "id": "kHnqNrxbtzHu"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HateDataset2(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, model):\n",
        "        dataset = dataset.to_pandas()\n",
        "        dataset = dataset[dataset['offensiveYN'] != '']\n",
        "        dataset.loc[dataset['offensiveYN'] == '0.5', 'offensiveYN'] = '1.0'\n",
        "        dataset = dataset.groupby(['post','offensiveYN']).size().reset_index(name='counts')\n",
        "        dataset = dataset.sort_values('counts', ascending=False).drop_duplicates('post')\n",
        "        dataset = datasets.Dataset.from_pandas(dataset)\n",
        "        label_encoder = LabelEncoder()\n",
        "        self.label = label_encoder.fit_transform(dataset['offensiveYN'])\n",
        "        self.post = dataset['post']\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model = model\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokenized_post = self.tokenizer(self.post[idx], return_tensors='pt',max_length=50, padding='max_length', truncation=True)\n",
        "        with torch.no_grad():\n",
        "            model_output = self.model(**tokenized_post)\n",
        "        last_hidden_state = model_output.last_hidden_state\n",
        "        return self.label[idx], last_hidden_state"
      ],
      "metadata": {
        "id": "BPpWhr-8LE5K"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_FC(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(BERT_FC, self).__init__()\n",
        "        self.fc1 = nn.Linear(50 * input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "NWdOne1-Hc6_"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERT_Arch_CNN, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(3, 768), padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=1)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(624, 2)\n",
        "        self.flat = nn.Flatten()\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, all_layers):\n",
        "        x = torch.transpose(torch.cat(tuple([t.unsqueeze(0) for t in all_layers]), 0), 0, 1)\n",
        "        torch.cuda.empty_cache()\n",
        "        x = self.pool(self.dropout(self.relu(self.conv(self.dropout(x)))))\n",
        "        x = self.fc(self.dropout(self.flat(self.dropout(x))))\n",
        "        return x"
      ],
      "metadata": {
        "id": "mR_aFVCF-JSS"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch_CNN_BiLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERT_Arch_CNN_BiLSTM, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels=13, out_channels=13, kernel_size=(3, 514), padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=1, stride=1)\n",
        "        self.bilstm = nn.LSTM(input_size = 768, hidden_size = 256, num_layers = 2, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.fc = nn.Linear(1300, 2)\n",
        "        self.flat = nn.Flatten()\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, all_layers):\n",
        "        x = torch.transpose(torch.cat(tuple([t.unsqueeze(0) for t in all_layers]), 0), 0, 1)\n",
        "        x, _ = self.bilstm(x.squeeze())\n",
        "        torch.cuda.empty_cache()\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(-1)\n",
        "        x = self.fc(x)\n",
        "        return x.unsqueeze(0)"
      ],
      "metadata": {
        "id": "KoTQ5jpo3zS7"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,test_dataloader):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    test_running_loss = 0.0\n",
        "    test_all_predictions = []\n",
        "    test_all_labels = []\n",
        "    criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for labels, all_layers in tqdm(test_dataloader, desc=f\"Testing\"):\n",
        "            labels = torch.tensor(labels)\n",
        "            for i in range(len(all_layers)):\n",
        "                all_layers[i] = all_layers[i].squeeze().unsqueeze(0)\n",
        "            all_layers = torch.stack(all_layers)\n",
        "            all_layers = all_layers.to(device)\n",
        "            labels=labels.to(device)\n",
        "            outputs = model(all_layers)\n",
        "            one_hot_targets = torch.zeros(1, 2).to(device)\n",
        "            one_hot_targets.scatter_(1, labels.unsqueeze(1), 1)\n",
        "            loss = criterion(outputs.squeeze(), one_hot_targets.squeeze())\n",
        "\n",
        "            test_running_loss += loss.item()\n",
        "\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            test_all_predictions.extend(predicted.cpu().tolist())\n",
        "            test_all_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "        test_epoch_loss = test_running_loss / len(test_dataloader)\n",
        "        test_epoch_accuracy = accuracy_score(test_all_labels, test_all_predictions)\n",
        "        test_epoch_f1 = f1_score(test_all_labels, test_all_predictions, average='macro')\n",
        "        print(f\"Testing, Loss: {test_epoch_loss:.4f}, Accuracy: {test_epoch_accuracy:.4f}, F1: {test_epoch_f1:.4f}\")\n",
        "        print(classification_report(test_all_labels,test_all_predictions))"
      ],
      "metadata": {
        "id": "2eBhKPIDJXX5"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate2(model,test_dataloader):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    test_all_predictions = []\n",
        "    test_all_labels = []\n",
        "    criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "    for labels, inputs in tqdm(test_dataloader, desc=f\"Testing\"):\n",
        "        inputs = torch.tensor(inputs[0])\n",
        "        labels = torch.tensor([labels[0]])\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs.squeeze())\n",
        "        one_hot_targets = torch.zeros(1, 2).to(device)\n",
        "        one_hot_targets.scatter_(1, labels.unsqueeze(1), 1)\n",
        "        loss = criterion(outputs, one_hot_targets.squeeze())\n",
        "        running_loss += loss.item()\n",
        "        predicted = torch.argmax(outputs.unsqueeze(0), dim=1)\n",
        "        test_all_predictions.extend(predicted.cpu().tolist())\n",
        "        test_all_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "    test_loss = running_loss / len(test_dataloader)\n",
        "    test_accuracy = accuracy_score(test_all_labels, test_all_predictions)\n",
        "    test_f1 = f1_score(test_all_labels, test_all_predictions, average='macro')\n",
        "\n",
        "    print(f\"Testing, Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}, F1: {test_f1:.4f}\")\n",
        "    print(classification_report(test_all_labels,test_all_predictions))"
      ],
      "metadata": {
        "id": "A2NoYcrhRwGj"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "7oRrzn_xJMve"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = HateDataset(test_dataset,tokenizer,bert_model,50)\n",
        "test_dataloader = DataLoader(test_data , batch_size=1 , shuffle=False)\n",
        "\n",
        "model = BERT_Arch_CNN()\n",
        "model.load_state_dict(torch.load('Model_BERT_CNN_10.pth'))\n",
        "evaluate(model,test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgbBOyCUu86n",
        "outputId": "b527671b-7371-4c5c-b8d0-69a292d8b0dc"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing:   0%|          | 0/2407 [00:00<?, ?it/s]<ipython-input-64-c4ca5b0ab59e>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(labels)\n",
            "Testing: 100%|██████████| 2407/2407 [06:46<00:00,  5.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing, Loss: 0.6527, Accuracy: 0.6647, F1: 0.6622\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.69      0.63      1003\n",
            "           1       0.75      0.64      0.69      1404\n",
            "\n",
            "    accuracy                           0.66      2407\n",
            "   macro avg       0.66      0.67      0.66      2407\n",
            "weighted avg       0.68      0.66      0.67      2407\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = HateDataset(test_dataset,tokenizer,bert_model,100)\n",
        "test_dataloader = DataLoader(test_data , batch_size=1 , shuffle=False)\n",
        "\n",
        "model = BERT_Arch_CNN_BiLSTM()\n",
        "model.load_state_dict(torch.load('Model_BERT_CNN_BiLSTM_10.pth'))\n",
        "evaluate(model,test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XtIry-pQLWa",
        "outputId": "fcce1a71-27a0-48f4-a865-d04ce13b1cdd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing:   0%|          | 0/2407 [00:00<?, ?it/s]<ipython-input-64-c4ca5b0ab59e>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(labels)\n",
            "Testing: 100%|██████████| 2407/2407 [10:37<00:00,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing, Loss: 0.5570, Accuracy: 0.7270, F1: 0.7204\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.69      0.68      1003\n",
            "           1       0.77      0.75      0.76      1404\n",
            "\n",
            "    accuracy                           0.73      2407\n",
            "   macro avg       0.72      0.72      0.72      2407\n",
            "weighted avg       0.73      0.73      0.73      2407\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = HateDataset2(test_dataset,tokenizer,bert_model)\n",
        "test_dataloader = DataLoader(test_data , batch_size=1 , shuffle=False)\n",
        "\n",
        "model = BERT_FC(768,128,2)\n",
        "model.load_state_dict(torch.load('Model_FC_10.pt'))\n",
        "evaluate2(model,test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge_h1eOdQJxt",
        "outputId": "8315e310-dcc7-4e00-c4a3-dab4018f869b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing:   0%|          | 0/2407 [00:00<?, ?it/s]<ipython-input-65-da7c046ea1dc>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  inputs = torch.tensor(inputs[0])\n",
            "Testing: 100%|██████████| 2407/2407 [06:39<00:00,  6.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing, Loss: 0.6219, Accuracy: 0.6897, F1: 0.6654\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.50      0.58      1003\n",
            "           1       0.70      0.82      0.76      1404\n",
            "\n",
            "    accuracy                           0.69      2407\n",
            "   macro avg       0.68      0.66      0.67      2407\n",
            "weighted avg       0.69      0.69      0.68      2407\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}